{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Hub Full Flowers\n",
    "\n",
    "Extract features with all of the tfhub models on the flowers dataset and compute/plot the TSNE of those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TSNE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHub version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, hub\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Hub version:\", hub.__version__)\n",
    "# print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n",
    "\n",
    "print(f\"GPU is available: {tf.test.is_built_with_cuda()}\")\n",
    "print(f\"GPU device: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "results_dir = Path(\"../work/results\")\n",
    "activations_dir = results_dir.joinpath(\"activations\")\n",
    "plots_dir = results_dir.joinpath(\"plots\")\n",
    "print(results_dir)\n",
    "print(activations_dir)\n",
    "print(plots_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare all of the model names and input dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"mobilenet_v3_small_100_224\"  # @param ['bit_s-r50x1', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'inception_v3', 'inception_resnet_v2', 'mobilenet_v2_100_224', 'mobilenet_v2_130_224', 'mobilenet_v2_140_224', 'mobilenet_v3_large_100_224', 'mobilenet_v3_large_075_224', 'mobilenet_v3_small_100_224', 'mobilenet_v3_small_075_224', 'nasnet_large', 'nasnet_mobile', 'pnasnet_large', 'resnet_v1_50', 'resnet_v1_101', 'resnet_v1_152', 'resnet_v2_50', 'resnet_v2_101', 'resnet_v2_152']\n",
    "\n",
    "model_handle_map = {\n",
    "    \"efficientnet_b0\": \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\",\n",
    "    \"efficientnet_b1\": \"https://tfhub.dev/tensorflow/efficientnet/b1/feature-vector/1\",\n",
    "    \"efficientnet_b2\": \"https://tfhub.dev/tensorflow/efficientnet/b2/feature-vector/1\",\n",
    "    \"efficientnet_b3\": \"https://tfhub.dev/tensorflow/efficientnet/b3/feature-vector/1\",\n",
    "    \"efficientnet_b4\": \"https://tfhub.dev/tensorflow/efficientnet/b4/feature-vector/1\",\n",
    "    \"efficientnet_b5\": \"https://tfhub.dev/tensorflow/efficientnet/b5/feature-vector/1\",\n",
    "    \"efficientnet_b6\": \"https://tfhub.dev/tensorflow/efficientnet/b6/feature-vector/1\",\n",
    "    \"efficientnet_b7\": \"https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1\",\n",
    "    \"bit_s-r50x1\": \"https://tfhub.dev/google/bit/s-r50x1/1\",\n",
    "    \"inception_v3\": \"https://tfhub.dev/google/imagenet/inception_v3/feature-vector/4\",\n",
    "    \"inception_resnet_v2\": \"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature-vector/4\",\n",
    "    \"resnet_v1_50\": \"https://tfhub.dev/google/imagenet/resnet_v1_50/feature-vector/4\",\n",
    "    \"resnet_v1_101\": \"https://tfhub.dev/google/imagenet/resnet_v1_101/feature-vector/4\",\n",
    "    \"resnet_v1_152\": \"https://tfhub.dev/google/imagenet/resnet_v1_152/feature-vector/4\",\n",
    "    \"resnet_v2_50\": \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature-vector/4\",\n",
    "    \"resnet_v2_101\": \"https://tfhub.dev/google/imagenet/resnet_v2_101/feature-vector/4\",\n",
    "    \"resnet_v2_152\": \"https://tfhub.dev/google/imagenet/resnet_v2_152/feature-vector/4\",\n",
    "    \"nasnet_large\": \"https://tfhub.dev/google/imagenet/nasnet_large/feature_vector/4\",\n",
    "    \"nasnet_mobile\": \"https://tfhub.dev/google/imagenet/nasnet_mobile/feature_vector/4\",\n",
    "    \"pnasnet_large\": \"https://tfhub.dev/google/imagenet/pnasnet_large/feature_vector/4\",\n",
    "    \"mobilenet_v2_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n",
    "    \"mobilenet_v2_130_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/feature_vector/4\",\n",
    "    \"mobilenet_v2_140_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4\",\n",
    "    \"mobilenet_v3_small_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\",\n",
    "    \"mobilenet_v3_small_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/feature_vector/5\",\n",
    "    \"mobilenet_v3_large_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5\",\n",
    "    \"mobilenet_v3_large_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_075_224/feature_vector/5\",\n",
    "}\n",
    "\n",
    "model_image_size_map = {\n",
    "    \"efficientnet_b0\": 224,\n",
    "    \"efficientnet_b1\": 240,\n",
    "    \"efficientnet_b2\": 260,\n",
    "    \"efficientnet_b3\": 300,\n",
    "    \"efficientnet_b4\": 380,\n",
    "    \"efficientnet_b5\": 456,\n",
    "    \"efficientnet_b6\": 528,\n",
    "    \"efficientnet_b7\": 600,\n",
    "    \"inception_v3\": 299,\n",
    "    \"inception_resnet_v2\": 299,\n",
    "    \"nasnet_large\": 331,\n",
    "    \"pnasnet_large\": 331,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SKIPPING: efficientnet_b0\n",
      "--- SKIPPING: efficientnet_b1\n",
      "--- SKIPPING: efficientnet_b2\n",
      "--- SKIPPING: efficientnet_b3\n",
      "--- SKIPPING: efficientnet_b4\n",
      "--- SKIPPING: efficientnet_b5\n",
      "--- SKIPPING: efficientnet_b6\n",
      "--- SKIPPING: efficientnet_b7\n",
      "--- SKIPPING: bit_s-r50x1\n",
      "Selected model: inception_v3 : https://tfhub.dev/google/imagenet/inception_v3/feature-vector/4\n",
      "Input size (299, 299)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 299, 299, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/inception_v3/feature-vector/4\n",
      "--- FAILURE: inception_v3\n",
      "Selected model: inception_resnet_v2 : https://tfhub.dev/google/imagenet/inception_resnet_v2/feature-vector/4\n",
      "Input size (299, 299)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 299, 299, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/inception_resnet_v2/feature-vector/4\n",
      "--- FAILURE: inception_resnet_v2\n",
      "Selected model: resnet_v1_50 : https://tfhub.dev/google/imagenet/resnet_v1_50/feature-vector/4\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/resnet_v1_50/feature-vector/4\n",
      "--- FAILURE: resnet_v1_50\n",
      "Selected model: resnet_v1_101 : https://tfhub.dev/google/imagenet/resnet_v1_101/feature-vector/4\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/resnet_v1_101/feature-vector/4\n",
      "--- FAILURE: resnet_v1_101\n",
      "Selected model: resnet_v1_152 : https://tfhub.dev/google/imagenet/resnet_v1_152/feature-vector/4\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/resnet_v1_152/feature-vector/4\n",
      "--- FAILURE: resnet_v1_152\n",
      "Selected model: resnet_v2_50 : https://tfhub.dev/google/imagenet/resnet_v2_50/feature-vector/4\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/resnet_v2_50/feature-vector/4\n",
      "--- FAILURE: resnet_v2_50\n",
      "Selected model: resnet_v2_101 : https://tfhub.dev/google/imagenet/resnet_v2_101/feature-vector/4\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/resnet_v2_101/feature-vector/4\n",
      "--- FAILURE: resnet_v2_101\n",
      "Selected model: resnet_v2_152 : https://tfhub.dev/google/imagenet/resnet_v2_152/feature-vector/4\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/resnet_v2_152/feature-vector/4\n",
      "--- FAILURE: resnet_v2_152\n",
      "Selected model: nasnet_large : https://tfhub.dev/google/imagenet/nasnet_large/feature_vector/4\n",
      "Input size (331, 331)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 331, 331, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/nasnet_large/feature_vector/4\n",
      "--- FAILURE: nasnet_large\n",
      "Selected model: nasnet_mobile : https://tfhub.dev/google/imagenet/nasnet_mobile/feature_vector/4\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/nasnet_mobile/feature_vector/4\n",
      "--- FAILURE: nasnet_mobile\n",
      "Selected model: pnasnet_large : https://tfhub.dev/google/imagenet/pnasnet_large/feature_vector/4\n",
      "Input size (331, 331)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 331, 331, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/pnasnet_large/feature_vector/4\n",
      "--- FAILURE: pnasnet_large\n",
      "Selected model: mobilenet_v2_100_224 : https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\n",
      "--- FAILURE: mobilenet_v2_100_224\n",
      "Selected model: mobilenet_v2_130_224 : https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/feature_vector/4\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/feature_vector/4\n",
      "--- FAILURE: mobilenet_v2_130_224\n",
      "Selected model: mobilenet_v2_140_224 : https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4\n",
      "--- FAILURE: mobilenet_v2_140_224\n",
      "Selected model: mobilenet_v3_small_100_224 : https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\n",
      "--- FAILURE: mobilenet_v3_small_100_224\n",
      "Selected model: mobilenet_v3_small_075_224 : https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/feature_vector/5\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/feature_vector/5\n",
      "--- FAILURE: mobilenet_v3_small_075_224\n",
      "Selected model: mobilenet_v3_large_100_224 : https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5\n",
      "--- FAILURE: mobilenet_v3_large_100_224\n",
      "Selected model: mobilenet_v3_large_075_224 : https://tfhub.dev/google/imagenet/mobilenet_v3_large_075_224/feature_vector/5\n",
      "Input size (224, 224)\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Generator shape 0: (32, 224, 224, 3)\n",
      "Generator shape 1: (32, 5)\n",
      "Building model with https://tfhub.dev/google/imagenet/mobilenet_v3_large_075_224/feature_vector/5\n",
      "--- FAILURE: mobilenet_v3_large_075_224\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all models\n",
    "for model_name, model_handle in model_handle_map.items():\n",
    "    try:\n",
    "        # Declare the savenames, etc. for if we're passing\n",
    "        data_save_name = activations_dir.joinpath(model_name + \".h5\")\n",
    "        plot_save_name = plots_dir.joinpath(model_name + \".jpg\")\n",
    "        # Skip this iteration if we already ran it\n",
    "        if data_save_name.exists() and plot_save_name.exists():\n",
    "            print(f\"--- SKIPPING: {model_name}\")\n",
    "            continue\n",
    "\n",
    "        # Show the selected model and handle\n",
    "        print(f\"Selected model: {model_name} : {model_handle}\")\n",
    "        # Get the squre dimension, defaulting to 224\n",
    "        pixels = model_image_size_map.get(model_name, 224)\n",
    "        IMAGE_SIZE = (pixels, pixels)\n",
    "        BATCH_SIZE = 32\n",
    "        print(f\"Input size {IMAGE_SIZE}\")\n",
    "\n",
    "        # Get the data generator\n",
    "        datagen_kwargs = dict(\n",
    "            rescale=1./255\n",
    "        )\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            interpolation=\"bilinear\",\n",
    "            shuffle=False\n",
    "        )\n",
    "        train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
    "        train_generator = train_datagen.flow_from_directory(data_dir, **dataflow_kwargs)\n",
    "        print(f\"Generator shape 0: {np.shape(next(train_generator)[0])}\")\n",
    "        print(f\"Generator shape 1: {np.shape(next(train_generator)[1])}\")\n",
    "        len(f\"Number of classes: {np.shape(train_generator.classes)}\")\n",
    "\n",
    "        # Build the model\n",
    "        print(\"Building model with\", model_handle)\n",
    "        model2 = tf.keras.Sequential([\n",
    "            # Explicitly define the input shape so the model can be properly\n",
    "            # loaded by the TFLiteConverter\n",
    "            tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "            hub.KerasLayer(model_handle)\n",
    "        ])\n",
    "        model.build((None,)+IMAGE_SIZE+(3,))\n",
    "        # model2.summary()\n",
    "\n",
    "        # Get the predicted features\n",
    "        results = model.predict(train_generator)\n",
    "        print(f\"Completed inference: {np.shape(results)}\")\n",
    "\n",
    "        # Compute the TSNE\n",
    "        tsne = TSNE().fit_transform(results)\n",
    "        print(f\"Calculated tsne: {np.shape(tsne)}\")\n",
    "\n",
    "        # Plot with masking\n",
    "        plt.figure()\n",
    "        plt.ylabel(\"TSNE[0]\")\n",
    "        plt.xlabel(\"TSNE[1]\")\n",
    "        plt.title(model_name)\n",
    "        plt.scatter(tsne[:, 0], tsne[:, 1], c = train_generator.classes)\n",
    "        plt.savefig(plot_save_name)\n",
    "\n",
    "        # Save the data\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_hdf(data_save_name,'df',mode='w')\n",
    "    except:\n",
    "        print(f\"--- FAILURE: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = pd.DataFrame(train_generator.classes)\n",
    "cl.to_csv(activations_dir.joinpath('classes.csv'),index=False, mode='w')\n",
    "np.shape(train_generator.classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
